{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer churn prediction\n",
    "This notebook uses a subset (128MB) of the full dataset available (12GB) for the convinence of manipulating data and build machine learning model locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, udf, to_timestamp, min, max, avg, when, length\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and read data as dataframe\n",
    "path = \"mini_sparkify_event_data.json\"\n",
    "df = spark.read.json(path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains 286500 rows and 18 columns\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print('The data set contains {} rows and {} columns'.format(num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "|        artist|     auth|firstName|gender|itemInSession|lastName|   length|level|       location|method|    page| registration|sessionId|     song|status|           ts|           userAgent|userId|\n",
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "|Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|Bakersfield, CA|   PUT|NextSong|1538173362000|       29|Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the fist row of the dataframe\n",
    "df.show(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist',\n",
       " 'auth',\n",
       " 'firstName',\n",
       " 'gender',\n",
       " 'itemInSession',\n",
       " 'lastName',\n",
       " 'length',\n",
       " 'level',\n",
       " 'location',\n",
       " 'method',\n",
       " 'page',\n",
       " 'registration',\n",
       " 'sessionId',\n",
       " 'song',\n",
       " 'status',\n",
       " 'ts',\n",
       " 'userAgent',\n",
       " 'userId']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check missing values and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \"\"\"Check the number of missing values in each columns and calculate the missing rate\n",
    "    \n",
    "    Arguments:\n",
    "        df {dataframe} -- spark dataframe\n",
    "        \n",
    "    Return: None    \n",
    "    \"\"\"\n",
    "    print('Column name         null count   null rate\\n')\n",
    "    for c in df.columns:\n",
    "        null_count = df.filter(df[c].isNull() | (df[c] == '') ).count() # Check whether each column has null value or empty string\n",
    "        null_rate = null_count/df.count() \n",
    "        print('{:15} | {:10} | {:10}'.format(c, null_count, null_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name         null count   null rate\n",
      "\n",
      "artist          |      58392 | 0.20381151832460734\n",
      "auth            |          0 |        0.0\n",
      "firstName       |       8346 | 0.029130890052356022\n",
      "gender          |       8346 | 0.029130890052356022\n",
      "itemInSession   |          0 |        0.0\n",
      "lastName        |       8346 | 0.029130890052356022\n",
      "length          |      58392 | 0.20381151832460734\n",
      "level           |          0 |        0.0\n",
      "location        |       8346 | 0.029130890052356022\n",
      "method          |          0 |        0.0\n",
      "page            |          0 |        0.0\n",
      "registration    |       8346 | 0.029130890052356022\n",
      "sessionId       |          0 |        0.0\n",
      "song            |      58392 | 0.20381151832460734\n",
      "status          |          0 |        0.0\n",
      "ts              |          0 |        0.0\n",
      "userAgent       |       8346 | 0.029130890052356022\n",
      "userId          |       8346 | 0.029130890052356022\n"
     ]
    }
   ],
   "source": [
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is shown above that columns such as 'firstName', 'gender', 'lastName', 'location', 'registration' and 'userAgent' all have the same numbers of missing values as 'userId', because these information are all 'userId' related. Since our purpose in this project is to analyze user behavior, it would be save to drop these rows with no user information for further analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without user id\n",
    "df_dropId = df.filter(df['userId'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|          artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|  Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|           Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "|Five Iron Frenzy|Logged In|    Micah|     M|           79|    Long|236.09424| free|Boston-Cambridge-...|   PUT|NextSong|1538331630000|        8|              Canada|   200|1538352180000|\"Mozilla/5.0 (Win...|     9|\n",
      "|    Adam Lambert|Logged In|    Colin|     M|           51| Freeman| 282.8273| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|   Time For Miracles|   200|1538352394000|Mozilla/5.0 (Wind...|    30|\n",
      "|          Enigma|Logged In|    Micah|     M|           80|    Long|262.71302| free|Boston-Cambridge-...|   PUT|NextSong|1538331630000|        8|Knocking On Forbi...|   200|1538352416000|\"Mozilla/5.0 (Win...|     9|\n",
      "|       Daft Punk|Logged In|    Colin|     M|           52| Freeman|223.60771| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|Harder Better Fas...|   200|1538352676000|Mozilla/5.0 (Wind...|    30|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dropId.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another case is that 3 song-related columns 'artist', 'length' and 'song' have the same number of missing values. Let's check their interaction with 'page' column to get some idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+-------------+\n",
      "|                page|count(song)|count(artist)|count(length)|\n",
      "+--------------------+-----------+-------------+-------------+\n",
      "|              Cancel|          0|            0|            0|\n",
      "|    Submit Downgrade|          0|            0|            0|\n",
      "|         Thumbs Down|          0|            0|            0|\n",
      "|                Home|          0|            0|            0|\n",
      "|           Downgrade|          0|            0|            0|\n",
      "|         Roll Advert|          0|            0|            0|\n",
      "|              Logout|          0|            0|            0|\n",
      "|       Save Settings|          0|            0|            0|\n",
      "|Cancellation Conf...|          0|            0|            0|\n",
      "|               About|          0|            0|            0|\n",
      "| Submit Registration|          0|            0|            0|\n",
      "|            Settings|          0|            0|            0|\n",
      "|               Login|          0|            0|            0|\n",
      "|            Register|          0|            0|            0|\n",
      "|     Add to Playlist|          0|            0|            0|\n",
      "|          Add Friend|          0|            0|            0|\n",
      "|            NextSong|     228108|       228108|       228108|\n",
      "|           Thumbs Up|          0|            0|            0|\n",
      "|                Help|          0|            0|            0|\n",
      "|             Upgrade|          0|            0|            0|\n",
      "|               Error|          0|            0|            0|\n",
      "|      Submit Upgrade|          0|            0|            0|\n",
      "+--------------------+-----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('page').agg({'artist':'count', 'length':'count', 'song':'count'}).show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three song related columns exclusively appears on 'NextSong' page. We will explore them further in feature engineering section.\n",
    "\n",
    "Now, with missing user ids removed, let's see how many users in total are registered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of unique users\n",
    "df.select('userId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---------------+-------------+---------+---------+--------------------+------+------+\n",
      "|     auth|level|           page| registration|   length|sessionId|                song|status|userId|\n",
      "+---------+-----+---------------+-------------+---------+---------+--------------------+------+------+\n",
      "|Logged In| paid|       NextSong|1538173362000|277.89016|       29|           Rockpools|   200|    30|\n",
      "|Logged In| free|       NextSong|1538331630000|236.09424|        8|              Canada|   200|     9|\n",
      "|Logged In| paid|       NextSong|1538173362000| 282.8273|       29|   Time For Miracles|   200|    30|\n",
      "|Logged In| free|       NextSong|1538331630000|262.71302|        8|Knocking On Forbi...|   200|     9|\n",
      "|Logged In| paid|       NextSong|1538173362000|223.60771|       29|Harder Better Fas...|   200|    30|\n",
      "|Logged In| free|       NextSong|1538331630000|208.29995|        8|      Don't Leave Me|   200|     9|\n",
      "|Logged In| free|       NextSong|1538331630000|260.46649|        8|         Run Run Run|   200|     9|\n",
      "|Logged In| paid|       NextSong|1538173362000|185.44281|       29|Passengers (Old A...|   200|    30|\n",
      "|Logged In| paid|Add to Playlist|1538173362000|     null|       29|                null|   200|    30|\n",
      "|Logged In| paid|       NextSong|1538173362000|134.47791|       29|          Fuck Kitty|   200|    30|\n",
      "+---------+-----+---------------+-------------+---------+---------+--------------------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pick some columns to get the detail\n",
    "df.select('auth','level','page','registration','length','sessionId','song','status','userId').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      auth| count|\n",
      "+----------+------+\n",
      "|Logged Out|  8249|\n",
      "| Cancelled|    52|\n",
      "|     Guest|    97|\n",
      "| Logged In|278102|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count occurences in each  'auth' category\n",
    "df.groupby('auth').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                page| count|\n",
      "+--------------------+------+\n",
      "|              Cancel|    52|\n",
      "|    Submit Downgrade|    63|\n",
      "|         Thumbs Down|  2546|\n",
      "|                Home| 14457|\n",
      "|           Downgrade|  2055|\n",
      "|         Roll Advert|  3933|\n",
      "|              Logout|  3226|\n",
      "|       Save Settings|   310|\n",
      "|Cancellation Conf...|    52|\n",
      "|               About|   924|\n",
      "| Submit Registration|     5|\n",
      "|            Settings|  1514|\n",
      "|               Login|  3241|\n",
      "|            Register|    18|\n",
      "|     Add to Playlist|  6526|\n",
      "|          Add Friend|  4277|\n",
      "|            NextSong|228108|\n",
      "|           Thumbs Up| 12551|\n",
      "|                Help|  1726|\n",
      "|             Upgrade|   499|\n",
      "|               Error|   258|\n",
      "|      Submit Upgrade|   159|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences in each page category\n",
    "df.groupby('page').count().show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|level| count|\n",
      "+-----+------+\n",
      "| free| 58338|\n",
      "| paid|228162|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences in each  level category\n",
    "df.groupby('level').count().show(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286500"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('userId').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. At the moment, the subscription ends and renewal doesn’t happen, or\n",
    "\n",
    "2. At the moment of the cancelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
