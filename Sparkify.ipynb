{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer churn prediction\n",
    "This notebook uses a subset (128MB) of the full dataset available (12GB) for the convinence of manipulating data and build machine learning model locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, udf, to_timestamp, min, max, avg, when, length\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and read data as dataframe\n",
    "path = \"mini_sparkify_event_data.json\"\n",
    "df = spark.read.json(path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains 286500 rows and 18 columns\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print('The data set contains {} rows and {} columns'.format(num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "|        artist|     auth|firstName|gender|itemInSession|lastName|   length|level|       location|method|    page| registration|sessionId|     song|status|           ts|           userAgent|userId|\n",
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "|Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|Bakersfield, CA|   PUT|NextSong|1538173362000|       29|Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "+--------------+---------+---------+------+-------------+--------+---------+-----+---------------+------+--------+-------------+---------+---------+------+-------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the fist row of the dataframe\n",
    "df.show(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist',\n",
       " 'auth',\n",
       " 'firstName',\n",
       " 'gender',\n",
       " 'itemInSession',\n",
       " 'lastName',\n",
       " 'length',\n",
       " 'level',\n",
       " 'location',\n",
       " 'method',\n",
       " 'page',\n",
       " 'registration',\n",
       " 'sessionId',\n",
       " 'song',\n",
       " 'status',\n",
       " 'ts',\n",
       " 'userAgent',\n",
       " 'userId']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check missing values and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \"\"\"Check the number of missing values in each columns and calculate the missing rate\n",
    "    \n",
    "    Arguments:\n",
    "        df {dataframe} -- spark dataframe\n",
    "        \n",
    "    Return: None    \n",
    "    \"\"\"\n",
    "    print('Column name         null count   null rate\\n')\n",
    "    for c in df.columns:\n",
    "        null_count = df.filter(df[c].isNull() | (df[c] == '') ).count() # Check whether each column has null value or empty string\n",
    "        null_rate = null_count/df.count() \n",
    "        print('{:15} | {:10} | {:10}'.format(c, null_count, null_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name         null count   null rate\n",
      "\n",
      "artist          |      58392 | 0.20381151832460734\n",
      "auth            |          0 |        0.0\n",
      "firstName       |       8346 | 0.029130890052356022\n",
      "gender          |       8346 | 0.029130890052356022\n",
      "itemInSession   |          0 |        0.0\n",
      "lastName        |       8346 | 0.029130890052356022\n",
      "length          |      58392 | 0.20381151832460734\n",
      "level           |          0 |        0.0\n",
      "location        |       8346 | 0.029130890052356022\n",
      "method          |          0 |        0.0\n",
      "page            |          0 |        0.0\n",
      "registration    |       8346 | 0.029130890052356022\n",
      "sessionId       |          0 |        0.0\n",
      "song            |      58392 | 0.20381151832460734\n",
      "status          |          0 |        0.0\n",
      "ts              |          0 |        0.0\n",
      "userAgent       |       8346 | 0.029130890052356022\n",
      "userId          |       8346 | 0.029130890052356022\n"
     ]
    }
   ],
   "source": [
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is shown above that columns such as 'firstName', 'gender', 'lastName', 'location', 'registration' and 'userAgent' all have 8346 missing values as 'userId', because these information are all 'userId' related. Since our purpose in this project is to analyze user behavior, it would be safe to drop those rows that have no user information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing user id\n",
    "df_dropId = df.filter((df['userId'] != '' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278154"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total rows left\n",
    "df_dropId.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another case is that 3 song-related columns 'artist', 'length' and 'song' have the same number of missing values. Let's check their interaction with 'page' column to get some idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+-------------+\n",
      "|                page|count(song)|count(artist)|count(length)|\n",
      "+--------------------+-----------+-------------+-------------+\n",
      "|              Cancel|          0|            0|            0|\n",
      "|    Submit Downgrade|          0|            0|            0|\n",
      "|         Thumbs Down|          0|            0|            0|\n",
      "|                Home|          0|            0|            0|\n",
      "|           Downgrade|          0|            0|            0|\n",
      "|         Roll Advert|          0|            0|            0|\n",
      "|              Logout|          0|            0|            0|\n",
      "|       Save Settings|          0|            0|            0|\n",
      "|Cancellation Conf...|          0|            0|            0|\n",
      "|               About|          0|            0|            0|\n",
      "| Submit Registration|          0|            0|            0|\n",
      "|            Settings|          0|            0|            0|\n",
      "|               Login|          0|            0|            0|\n",
      "|            Register|          0|            0|            0|\n",
      "|     Add to Playlist|          0|            0|            0|\n",
      "|          Add Friend|          0|            0|            0|\n",
      "|            NextSong|     228108|       228108|       228108|\n",
      "|           Thumbs Up|          0|            0|            0|\n",
      "|                Help|          0|            0|            0|\n",
      "|             Upgrade|          0|            0|            0|\n",
      "|               Error|          0|            0|            0|\n",
      "|      Submit Upgrade|          0|            0|            0|\n",
      "+--------------------+-----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('page').agg({'artist':'count', 'length':'count', 'song':'count'}).show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three song related columns exclusively relate with 'NextSong' in page column. A user is unlikely to churn simply because of the names of the artist or song. So these columns could be dropped. As for the lengh of the song, We will explore it further in feature engineering section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'artist' and 'song' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_dropId.drop('artist', 'song')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with missing user ids removed, let's see how many users in total are registered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 226 unique users in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check number of unique users\n",
    "n_users = df.select('userId').dropDuplicates().count()\n",
    "print('There are {} unique users in the dataset.'.format(n_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since user ids are unique values to idendify users, we don't need extra 'firstName' and 'lastName' columns. Additionally, a user is unlikely to churn simply because of his/her own location. So we will drop these columns, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_drop.drop('firstName','lastName', 'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+---------+-----+------+--------+-------------+---------+------+-------------+--------------------+------+\n",
      "|     auth|gender|itemInSession|   length|level|method|    page| registration|sessionId|status|           ts|           userAgent|userId|\n",
      "+---------+------+-------------+---------+-----+------+--------+-------------+---------+------+-------------+--------------------+------+\n",
      "|Logged In|     M|           50|277.89016| paid|   PUT|NextSong|1538173362000|       29|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "|Logged In|     M|           79|236.09424| free|   PUT|NextSong|1538331630000|        8|   200|1538352180000|\"Mozilla/5.0 (Win...|     9|\n",
      "|Logged In|     M|           51| 282.8273| paid|   PUT|NextSong|1538173362000|       29|   200|1538352394000|Mozilla/5.0 (Wind...|    30|\n",
      "|Logged In|     M|           80|262.71302| free|   PUT|NextSong|1538331630000|        8|   200|1538352416000|\"Mozilla/5.0 (Win...|     9|\n",
      "|Logged In|     M|           52|223.60771| paid|   PUT|NextSong|1538173362000|       29|   200|1538352676000|Mozilla/5.0 (Wind...|    30|\n",
      "+---------+------+-------------+---------+-----+------+--------+-------------+---------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|summary|     itemInSession|        registration|            length|         sessionId|            status|                  ts|\n",
      "+-------+------------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|  count|            278154|              278154|            228108|            278154|            278154|              278154|\n",
      "|   mean|114.89918174824018|1.535358834085619...|249.11718197783583|1042.5616241362698|209.10321620397335|1.540958915431790...|\n",
      "| stddev|129.85172939948959|3.2913216163281236E9| 99.23517921058313| 726.5010362219864|  30.1513888513279|1.5068287123356583E9|\n",
      "|    min|                 0|       1521380675000|           0.78322|                 1|               200|       1538352117000|\n",
      "|    max|              1321|       1543247354000|        3024.66567|              2474|               404|       1543799476000|\n",
      "+-------+------------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at numerical columns\n",
    "df_drop.select('itemInSession','registration','length','sessionId', 'status','ts').describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     auth| count|\n",
      "+---------+------+\n",
      "|Cancelled|    52|\n",
      "|Logged In|278102|\n",
      "+---------+------+\n",
      "\n",
      "+------+------+\n",
      "|gender| count|\n",
      "+------+------+\n",
      "|     F|154578|\n",
      "|     M|123576|\n",
      "+------+------+\n",
      "\n",
      "+-----+------+\n",
      "|level| count|\n",
      "+-----+------+\n",
      "| free| 55721|\n",
      "| paid|222433|\n",
      "+-----+------+\n",
      "\n",
      "+------+------+\n",
      "|method| count|\n",
      "+------+------+\n",
      "|   PUT|257818|\n",
      "|   GET| 20336|\n",
      "+------+------+\n",
      "\n",
      "+--------------------+------+\n",
      "|                page| count|\n",
      "+--------------------+------+\n",
      "|              Cancel|    52|\n",
      "|    Submit Downgrade|    63|\n",
      "|         Thumbs Down|  2546|\n",
      "|                Home| 10082|\n",
      "|           Downgrade|  2055|\n",
      "|         Roll Advert|  3933|\n",
      "|              Logout|  3226|\n",
      "|       Save Settings|   310|\n",
      "|Cancellation Conf...|    52|\n",
      "|               About|   495|\n",
      "|            Settings|  1514|\n",
      "|     Add to Playlist|  6526|\n",
      "|          Add Friend|  4277|\n",
      "|            NextSong|228108|\n",
      "|           Thumbs Up| 12551|\n",
      "|                Help|  1454|\n",
      "|             Upgrade|   499|\n",
      "|               Error|   252|\n",
      "|      Submit Upgrade|   159|\n",
      "+--------------------+------+\n",
      "\n",
      "+--------------------+-----+\n",
      "|           userAgent|count|\n",
      "+--------------------+-----+\n",
      "|\"Mozilla/5.0 (Mac...|  240|\n",
      "|\"Mozilla/5.0 (Win...| 5238|\n",
      "|Mozilla/5.0 (X11;...|   62|\n",
      "|\"Mozilla/5.0 (Mac...|18448|\n",
      "|\"Mozilla/5.0 (Mac...| 1262|\n",
      "|Mozilla/5.0 (Maci...| 2442|\n",
      "|Mozilla/5.0 (Wind...| 3214|\n",
      "|Mozilla/5.0 (Wind...| 5989|\n",
      "|Mozilla/5.0 (comp...| 8624|\n",
      "|\"Mozilla/5.0 (Win...| 7624|\n",
      "|Mozilla/5.0 (Maci...|10300|\n",
      "|\"Mozilla/5.0 (Win...| 2168|\n",
      "|\"Mozilla/5.0 (iPh...| 1976|\n",
      "|\"Mozilla/5.0 (Win...|15395|\n",
      "|Mozilla/5.0 (Wind...|16700|\n",
      "|Mozilla/5.0 (comp...| 1245|\n",
      "|Mozilla/5.0 (comp...|  815|\n",
      "|\"Mozilla/5.0 (Mac...|  235|\n",
      "|\"Mozilla/5.0 (Mac...|  512|\n",
      "|\"Mozilla/5.0 (Win...|14598|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|100010|  381|\n",
      "|200002|  474|\n",
      "|   125|   11|\n",
      "|    51| 2464|\n",
      "|   124| 4825|\n",
      "|     7|  201|\n",
      "|    54| 3437|\n",
      "|    15| 2278|\n",
      "|   155| 1002|\n",
      "|   132| 2304|\n",
      "|   154|  118|\n",
      "|100014|  310|\n",
      "|   101| 2149|\n",
      "|    11|  848|\n",
      "|   138| 2469|\n",
      "|300017| 4428|\n",
      "|    29| 3603|\n",
      "|    69| 1342|\n",
      "|100021|  319|\n",
      "|    42| 4257|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at categorical columns\n",
    "# and count occurences in each category in each column\n",
    "cat_cols = ['auth', 'gender', 'level', 'method', 'page', 'userAgent', 'userId']\n",
    "for c in cat_cols:\n",
    "    grouped = df_drop.groupby(c).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'status', 'method' and 'userAgent'column contains network related records, can also be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_drop.drop('status','method','userAgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+---------+-----+--------+-------------+---------+-------------+------+\n",
      "|     auth|gender|itemInSession|   length|level|    page| registration|sessionId|           ts|userId|\n",
      "+---------+------+-------------+---------+-----+--------+-------------+---------+-------------+------+\n",
      "|Logged In|     M|           50|277.89016| paid|NextSong|1538173362000|       29|1538352117000|    30|\n",
      "|Logged In|     M|           79|236.09424| free|NextSong|1538331630000|        8|1538352180000|     9|\n",
      "|Logged In|     M|           51| 282.8273| paid|NextSong|1538173362000|       29|1538352394000|    30|\n",
      "|Logged In|     M|           80|262.71302| free|NextSong|1538331630000|        8|1538352416000|     9|\n",
      "|Logged In|     M|           52|223.60771| paid|NextSong|1538173362000|       29|1538352676000|    30|\n",
      "+---------+------+-------------+---------+-----+--------+-------------+---------+-------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show cleaned dataset\n",
    "df_drop.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we cleaned the dataframe by dropping  rows with mising user id and columns that are not relevant. The next step is to define churn and perform exploratory data analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                page| count|\n",
      "+--------------------+------+\n",
      "|              Cancel|    52|\n",
      "|    Submit Downgrade|    63|\n",
      "|         Thumbs Down|  2546|\n",
      "|                Home| 10082|\n",
      "|           Downgrade|  2055|\n",
      "|         Roll Advert|  3933|\n",
      "|              Logout|  3226|\n",
      "|       Save Settings|   310|\n",
      "|Cancellation Conf...|    52|\n",
      "|               About|   495|\n",
      "|            Settings|  1514|\n",
      "|     Add to Playlist|  6526|\n",
      "|          Add Friend|  4277|\n",
      "|            NextSong|228108|\n",
      "|           Thumbs Up| 12551|\n",
      "|                Help|  1454|\n",
      "|             Upgrade|   499|\n",
      "|               Error|   252|\n",
      "|      Submit Upgrade|   159|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences in each page category\n",
    "df_drop.groupby('page').count().show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. At the moment, the subscription ends and renewal doesnâ€™t happen, or\n",
    "\n",
    "2. At the moment of the cancelation.\n",
    "\n",
    "3. Downgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
